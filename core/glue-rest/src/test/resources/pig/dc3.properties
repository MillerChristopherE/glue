fs.default.name=hdfs://namenode302-dc3:8020/
mapred.job.tracker=namenode302-dc3:8021
mapred.job.reuse.jvm.num.tasks=-1
mapred.job.queue.name=Queue_2.4
dfs.replication=3
mapred.child.java.opts=-Xmx2048m -Xms1024m -Djava.library.path=/opt/hadoop/lib/native/Linux-amd64-64
mapred.compress.map.output=true
map.output.compression.type=BLOCK

mapred.map.tasks.speculative.execution=false
mapred.reduce.tasks.speculative.execution=false
mapred.output.compression.codec=com.hadoop.compression.lzo.LzoCodec
mapred.map.output.compression.codec=com.hadoop.compression.lzo.LzoCodec


# log4jconf log4j configuration file
# log4jconf=./conf/log4j.properties

# a file that contains pig script
#file=

# load jarfile, colon separated
#jar=

#verbose print all log messages to screen (default to print only INFO and above to screen)
#verbose=true

#exectype local|mapreduce, mapreduce is default
#exectype=local

#pig.logfile=

#Do not spill temp files smaller than this size (bytes)
#pig.spill.size.threshold=5000000
#EXPERIMENT: Activate garbage collection when spilling a file bigger than this size (bytes)
#This should help reduce the number of files being spilled.
#pig.spill.gc.activation.size=40000000

#the following two parameters are to help estimate the reducer number
#pig.exec.reducers.bytes.per.reducer=1000000000
#pig.exec.reducers.max=999
