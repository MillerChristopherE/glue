fs.default.name=
mapred.job.tracker=
#mapred.job.reuse.jvm.num.tasks=-1
#mapred.job.queue.name=
#dfs.replication=3
#mapred.compress.map.output=true
map.output.compression.type=RECORD

#mapred.map.tasks.speculative.execution=false
#mapred.reduce.tasks.speculative.execution=false
#mapred.output.compression.codec=
##mapred.map.output.compression.codec=


#mapred.child.java.opts=-Xmx2048m -XX:+UseConcMarkSweepGC -Xms1024m -XX:-UseGCOverheadLimit -XX:+DoEscapeAnalysis -XX:+UseCompressedOops
#io.sort.mb=310

#io.buffer.size=16384 65536
# Pig configuration file. All values can be overwritten by command line arguments.
# see bin/pig -help

# log4jconf log4j configuration file
# log4jconf=./conf/log4j.properties

# brief logging (no timestamps)
brief=false

# clustername, name of the hadoop jobtracker. If no port is defined port 50020 will be used. 
#cluster

#debug level, INFO is default
debug=INFO

# a file that contains pig script
#file=

# load jarfile, colon separated
#jar=

#verbose print all log messages to screen (default to print only INFO and above to screen)
verbose=false

